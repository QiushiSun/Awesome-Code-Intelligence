## Paper Collection for Preference Optimization


1. [Preprint] **DSTC: Direct Preference Learning with Only Self-Generated Tests and Code to Improve Code LMs.** [![arXiv](https://img.shields.io/badge/arXiv-2411.13611-b31b1b.svg)](https://arxiv.org/abs/2411.13611), 2024.11

   *Zhihan Liu, Shenao Zhang, Zhaoran Wang*

2. [Preprint] **CodeLutra: Boosting LLM Code Generation via Preference-Guided Refinement.** [![arXiv](https://img.shields.io/badge/arXiv-2411.05199-b31b1b.svg)](https://arxiv.org/abs/2411.05199), 2024.11

   *Leitian Tao, Xiang Chen, Tong Yu, Tung Mai, Ryan Rossi, Yixuan Li, Saayan Mitra*

3. [Preprint] **CodeDPO: Aligning Code Models with Self Generated and Verified Source Code.** [![arXiv](https://img.shields.io/badge/arXiv-2410.05605-b31b1b.svg)](https://arxiv.org/abs/2410.05605), 2024.10

   *Kechi Zhang, Ge Li, Yihong Dong, Jingjing Xu, Jun Zhang, Jing Su, Yongfei Liu, Zhi Jin*

4. [Preprint] **Code-Optimise: Self-Generated Preference Data for Correctness and Efficiency.** [![arXiv](https://img.shields.io/badge/arXiv-2406.12502-b31b1b.svg)](https://arxiv.org/abs/2406.12502), 2024.06

   *Leonidas Gee, Milan Gritta, Gerasimos Lampouras, Ignacio Iacobacci*

5. [Preprint] **PLUM: Improving Code LMs with Execution-Guided On-Policy Preference Learning Driven By Synthetic Test Cases.** [![arXiv](https://img.shields.io/badge/arXiv-2406.06887-b31b1b.svg)](https://arxiv.org/abs/2406.06887), 2024.06

   *Dylan Zhang, Shizhe Diao, Xueyan Zou, Hao Peng*

